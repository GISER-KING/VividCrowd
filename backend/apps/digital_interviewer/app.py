"""
æ•°å­—é¢è¯•å®˜åº”ç”¨ - FastAPIè·¯ç”±
"""
import os
import hashlib
import uuid
from typing import List, Optional
from fastapi import APIRouter, UploadFile, File, Form, HTTPException, WebSocket, WebSocketDisconnect, Depends
from fastapi.responses import JSONResponse
from sqlalchemy.orm import Session
from datetime import datetime

from backend.core.database import get_digital_interviewer_db
from backend.models.db_models import (
    InterviewerProfile,
    InterviewerProfileRegistry,
    InterviewSession,
    InterviewRound,
    InterviewEvaluation,
    InterviewKnowledge,
    InterviewExperienceSet
)
from backend.apps.digital_interviewer.services.profile_parser import InterviewerProfileParser
from backend.apps.digital_interviewer.services.experience_service import ExperienceService

# åˆ›å»ºè·¯ç”±å™¨
router = APIRouter(prefix="/digital-interviewer", tags=["æ•°å­—é¢è¯•å®˜"])

# æ–‡ä»¶ä¸Šä¼ ç›®å½•
UPLOAD_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "data", "interviewer_uploads")
os.makedirs(UPLOAD_DIR, exist_ok=True)

VIDEO_DIR = os.path.join(UPLOAD_DIR, "videos")
os.makedirs(VIDEO_DIR, exist_ok=True)

PROFILE_DIR = os.path.join(UPLOAD_DIR, "profiles")
os.makedirs(PROFILE_DIR, exist_ok=True)

# é¢ç»æ–‡ä»¶ä¸Šä¼ ç›®å½•
EXPERIENCE_DIR = os.path.join(UPLOAD_DIR, "experiences")
os.makedirs(EXPERIENCE_DIR, exist_ok=True)

# è™šæ‹Ÿäººå½¢è±¡ç›®å½•ï¼ˆç‹¬ç«‹çš„è™šæ‹Ÿäººå½¢è±¡åº“ï¼‰
DIGITAL_HUMANS_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "data", "digital_humans")
os.makedirs(DIGITAL_HUMANS_DIR, exist_ok=True)


def scan_all_digital_humans():
    """
    å¯åŠ¨æ—¶æ‰«ææ‰€æœ‰è™šæ‹Ÿäººå½¢è±¡
    """
    from loguru import logger
    from backend.core.database import get_digital_interviewer_db
    from backend.models.db_models import DigitalHuman

    logger.info("ğŸ­ å¼€å§‹æ‰«æè™šæ‹Ÿäººå½¢è±¡åº“...")

    db = next(get_digital_interviewer_db())
    try:
        if not os.path.exists(DIGITAL_HUMANS_DIR):
            logger.warning(f"âš ï¸ è™šæ‹Ÿäººå½¢è±¡ç›®å½•ä¸å­˜åœ¨: {DIGITAL_HUMANS_DIR}")
            return 0

        total_count = 0

        # éå†æ‰€æœ‰å­ç›®å½•
        for human_name in os.listdir(DIGITAL_HUMANS_DIR):
            human_path = os.path.join(DIGITAL_HUMANS_DIR, human_name)

            # åªå¤„ç†ç›®å½•
            if not os.path.isdir(human_path):
                continue

            logger.info(f"ğŸ­ æ‰«æè™šæ‹Ÿäººå½¢è±¡: {human_name}")

            # æ£€æŸ¥4ä¸ªå¿…éœ€çš„è§†é¢‘æ–‡ä»¶
            video_files = {
                'video_idle': 'idle.mp4',
                'video_speaking': 'speaking.mp4',
                'video_listening': 'listening.mp4',
                'video_thinking': 'thinking.mp4'
            }

            videos = {}
            all_found = True
            for field_name, filename in video_files.items():
                file_path = os.path.join(human_path, filename)
                if os.path.exists(file_path):
                    # è¿”å›ç›¸å¯¹è·¯å¾„ï¼Œä¾¿äºå‰ç«¯è®¿é—®
                    relative_path = f"/data/digital_humans/{human_name}/{filename}"
                    videos[field_name] = relative_path
                    logger.debug(f"  âœ… {filename}")
                else:
                    logger.warning(f"  âš ï¸ ç¼ºå°‘ {filename}")
                    all_found = False

            if not all_found:
                logger.warning(f"  âš ï¸ è™šæ‹Ÿäººå½¢è±¡ {human_name} è§†é¢‘ä¸å®Œæ•´ï¼Œè·³è¿‡")
                continue

            # æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦å·²å­˜åœ¨è¯¥å½¢è±¡
            existing = db.query(DigitalHuman).filter_by(name=human_name).first()

            if existing:
                # æ›´æ–°ç°æœ‰è®°å½•
                for key, value in videos.items():
                    setattr(existing, key, value)
                existing.is_active = True
                logger.info(f"  ğŸ”„ æ›´æ–°è™šæ‹Ÿäººå½¢è±¡: {human_name}")
            else:
                # åˆ›å»ºæ–°è®°å½•
                # è‡ªåŠ¨ç”Ÿæˆæ˜¾ç¤ºåç§°ï¼ˆå°†ä¸‹åˆ’çº¿æ›¿æ¢ä¸ºç©ºæ ¼å¹¶é¦–å­—æ¯å¤§å†™ï¼‰
                display_name = human_name.replace('_', ' ').title()

                # å°è¯•ä»åç§°ä¸­æå–æ€§åˆ«å’Œé£æ ¼
                gender = None
                style = None
                if 'male' in human_name.lower():
                    gender = 'male'
                elif 'female' in human_name.lower():
                    gender = 'female'

                if 'formal' in human_name.lower():
                    style = 'formal'
                elif 'casual' in human_name.lower():
                    style = 'casual'
                elif 'tech' in human_name.lower():
                    style = 'tech'

                human = DigitalHuman(
                    name=human_name,
                    display_name=display_name,
                    gender=gender,
                    style=style,
                    is_active=True,
                    is_default=(human_name == 'default'),
                    **videos
                )
                db.add(human)
                logger.info(f"  âœ¨ æ–°å¢è™šæ‹Ÿäººå½¢è±¡: {display_name}")

            total_count += 1

        db.commit()
        logger.info(f"âœ… æ‰«æå®Œæˆï¼Œå…±æ‰¾åˆ° {total_count} ä¸ªè™šæ‹Ÿäººå½¢è±¡")
        return total_count

    except Exception as e:
        logger.error(f"âŒ æ‰«æå¤±è´¥: {str(e)}")
        logger.exception(e)
        return 0
    finally:
        db.close()


@router.get("/interviewers")
async def get_interviewers(db: Session = Depends(get_digital_interviewer_db)):
    """è·å–æ‰€æœ‰é¢è¯•å®˜åˆ—è¡¨"""
    interviewers = db.query(InterviewerProfile).all()
    return {"interviewers": [interviewer.to_dict() for interviewer in interviewers]}


@router.get("/digital-humans")
async def get_digital_humans(db: Session = Depends(get_digital_interviewer_db)):
    """è·å–æ‰€æœ‰å¯ç”¨çš„è™šæ‹Ÿäººå½¢è±¡"""
    from backend.models.db_models import DigitalHuman

    humans = db.query(DigitalHuman).filter_by(is_active=True).all()

    return {
        "digital_humans": [human.to_dict() for human in humans]
    }


@router.post("/interviewers/upload")
async def upload_interviewer_profile(
    file: UploadFile = File(...),
    db: Session = Depends(get_digital_interviewer_db)
):
    """ä¸Šä¼ é¢è¯•å®˜ç”»åƒæ–‡ä»¶"""
    from loguru import logger

    try:
        logger.info(f"ğŸ“¤ å¼€å§‹ä¸Šä¼ é¢è¯•å®˜ç”»åƒ: {file.filename}")

        # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
        content = await file.read()
        file_hash = hashlib.md5(content).hexdigest()
        logger.info(f"ğŸ“ æ–‡ä»¶å“ˆå¸Œ: {file_hash}")

        # æ£€æŸ¥æ˜¯å¦å·²å¯¼å…¥
        existing = db.query(InterviewerProfileRegistry).filter_by(file_hash=file_hash).first()
        if existing:
            logger.info(f"âš ï¸ æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡å¯¼å…¥")
            return {"message": "è¯¥æ–‡ä»¶å·²å¯¼å…¥", "interviewer_id": existing.interviewer_profile_id}

        # ä¿å­˜æ–‡ä»¶
        file_path = os.path.join(PROFILE_DIR, file.filename)
        with open(file_path, 'wb') as f:
            f.write(content)
        logger.info(f"ğŸ’¾ æ–‡ä»¶å·²ä¿å­˜åˆ°: {file_path}")

        # è§£æç”»åƒ
        logger.info(f"ğŸ” å¼€å§‹è§£æç”»åƒæ–‡ä»¶...")
        parser = InterviewerProfileParser()
        profile_data = await parser.parse_file(file_path)
        logger.info(f"âœ… è§£æå®Œæˆï¼Œæå–åˆ°çš„æ•°æ®: {profile_data.keys()}")
        logger.info(f"ğŸ“‹ å§“å: {profile_data.get('name', 'N/A')}")
        logger.info(f"ğŸ“‹ ä¸“ä¸šé¢†åŸŸ: {profile_data.get('expertise_areas', 'N/A')}")

        # ç”Ÿæˆç³»ç»Ÿæç¤ºè¯
        system_prompt = await parser.generate_system_prompt(profile_data)
        profile_data['system_prompt'] = system_prompt
        logger.info(f"ğŸ’¬ ç³»ç»Ÿæç¤ºè¯å·²ç”Ÿæˆ (é•¿åº¦: {len(system_prompt)})")

        # ä¿å­˜åˆ°æ•°æ®åº“
        interviewer = InterviewerProfile(**profile_data)
        db.add(interviewer)
        db.commit()
        db.refresh(interviewer)
        logger.info(f"âœ… é¢è¯•å®˜å·²ä¿å­˜åˆ°æ•°æ®åº“ï¼ŒID: {interviewer.id}")

        # æ³¨å†Œæ–‡ä»¶
        registry = InterviewerProfileRegistry(
            filename=file.filename,
            file_hash=file_hash,
            interviewer_profile_id=interviewer.id,
            interviewer_name=interviewer.name
        )
        db.add(registry)
        db.commit()
        logger.info(f"âœ… æ–‡ä»¶å·²æ³¨å†Œ")

        return {"message": "ä¸Šä¼ æˆåŠŸ", "interviewer": interviewer.to_dict()}

    except Exception as e:
        logger.error(f"âŒ ä¸Šä¼ å¤±è´¥: {str(e)}")
        logger.exception(e)
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/interviewers/{interviewer_id}")
async def delete_interviewer(
    interviewer_id: int,
    db: Session = Depends(get_digital_interviewer_db)
):
    """åˆ é™¤é¢è¯•å®˜"""
    try:
        interviewer = db.query(InterviewerProfile).filter_by(id=interviewer_id).first()
        if not interviewer:
            raise HTTPException(status_code=404, detail="é¢è¯•å®˜ä¸å­˜åœ¨")

        db.delete(interviewer)
        db.commit()

        return {"message": "åˆ é™¤æˆåŠŸ"}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/sessions/start")
async def start_interview_session(
    interviewer_id: int = Form(...),
    interview_type: str = Form(...),
    candidate_name: str = Form(None),
    digital_human_id: int = Form(None),
    experience_set_ids: str = Form(None),  # JSONæ•°ç»„å­—ç¬¦ä¸²ï¼Œå¦‚ "[1,2,3]"
    experience_mode: str = Form("none"),   # none/reference/strict/mixed
    max_rounds: int = Form(5),             # æœ€å¤§é¢è¯•è½®æ•°ï¼Œé»˜è®¤5è½®
    db: Session = Depends(get_digital_interviewer_db)
):
    """å¼€å§‹é¢è¯•ä¼šè¯"""
    from backend.models.db_models import DigitalHuman
    import json as json_module

    try:
        interviewer = db.query(InterviewerProfile).filter_by(id=interviewer_id).first()
        if not interviewer:
            raise HTTPException(status_code=404, detail="é¢è¯•å®˜ä¸å­˜åœ¨")

        # éªŒè¯è™šæ‹Ÿäººå½¢è±¡
        digital_human = None
        if digital_human_id:
            digital_human = db.query(DigitalHuman).filter_by(id=digital_human_id).first()
            if not digital_human:
                raise HTTPException(status_code=404, detail="è™šæ‹Ÿäººå½¢è±¡ä¸å­˜åœ¨")

        # è§£æé¢ç»é›†IDåˆ—è¡¨
        parsed_set_ids = []
        if experience_set_ids and experience_set_ids.strip():
            try:
                parsed_set_ids = json_module.loads(experience_set_ids)
                if not isinstance(parsed_set_ids, list):
                    parsed_set_ids = []
            except:
                parsed_set_ids = []

        # åˆ›å»ºä¼šè¯
        session_id = str(uuid.uuid4())
        session = InterviewSession(
            session_id=session_id,
            interviewer_profile_id=interviewer_id,
            digital_human_id=digital_human_id,
            interviewer_name=interviewer.name,
            interviewer_title=interviewer.title,
            interview_type=interview_type,
            candidate_name=candidate_name,
            max_rounds=max_rounds,
            status="in_progress"
        )

        db.add(session)
        db.commit()
        db.refresh(session)

        # è¿”å›ä¼šè¯ä¿¡æ¯å’Œè™šæ‹Ÿäººå½¢è±¡è§†é¢‘è·¯å¾„
        response_data = {
            "message": "ä¼šè¯åˆ›å»ºæˆåŠŸ",
            "session_id": session.session_id,
            "session": session.to_dict(),
            "experience_set_ids": parsed_set_ids,
            "experience_mode": experience_mode,
            "max_rounds": max_rounds
        }

        if digital_human:
            # æ„å»ºå®Œæ•´çš„è§†é¢‘URLï¼ˆåŒ…å«åç«¯æœåŠ¡å™¨åœ°å€ï¼‰
            base_url = "http://localhost:8001"  # åç«¯æœåŠ¡å™¨åœ°å€ï¼ˆæ³¨æ„æ˜¯8001ç«¯å£ï¼‰
            response_data["digital_human_videos"] = {
                "idle": f"{base_url}{digital_human.video_idle}",
                "speaking": f"{base_url}{digital_human.video_speaking}",
                "listening": f"{base_url}{digital_human.video_listening}",
                "thinking": f"{base_url}{digital_human.video_thinking}"
            }

        return response_data

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/sessions/{session_id}")
async def get_interview_session(
    session_id: str,
    db: Session = Depends(get_digital_interviewer_db)
):
    """è·å–é¢è¯•ä¼šè¯è¯¦æƒ…"""
    session = db.query(InterviewSession).filter_by(session_id=session_id).first()
    if not session:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

    return {"session": session.to_dict()}


@router.get("/sessions/{session_id}/rounds")
async def get_interview_rounds(
    session_id: str,
    db: Session = Depends(get_digital_interviewer_db)
):
    """è·å–é¢è¯•è½®æ¬¡æ•°æ®"""
    from backend.models.db_models import InterviewRound

    session = db.query(InterviewSession).filter_by(session_id=session_id).first()
    if not session:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

    rounds = db.query(InterviewRound).filter_by(session_id=session.id).order_by(InterviewRound.round_number).all()
    return {"rounds": [r.to_dict() for r in rounds]}


@router.get("/sessions/{session_id}/evaluation")
async def get_interview_evaluation(
    session_id: str,
    db: Session = Depends(get_digital_interviewer_db)
):
    """è·å–é¢è¯•è¯„ä¼°ç»“æœ"""
    from backend.models.db_models import InterviewEvaluation, InterviewRound

    session = db.query(InterviewSession).filter_by(session_id=session_id).first()
    if not session:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

    # å°è¯•è·å–å·²ä¿å­˜çš„è¯„ä¼°
    evaluation = db.query(InterviewEvaluation).filter_by(session_id=session.id).first()

    if evaluation:
        return {"evaluation": evaluation.to_dict()}

    # å¦‚æœæ²¡æœ‰ä¿å­˜çš„è¯„ä¼°ï¼Œä»è½®æ¬¡æ•°æ®ä¸­æ±‡æ€»
    rounds = db.query(InterviewRound).filter_by(session_id=session.id).all()

    if not rounds:
        # æ²¡æœ‰ä»»ä½•è½®æ¬¡æ•°æ®ï¼Œè¿”å›ç©ºè¯„ä¼°
        return {
            "evaluation": {
                "technical_score": 0,
                "communication_score": 0,
                "problem_solving_score": 0,
                "cultural_fit_score": 0,
                "total_score": 0,
                "performance_level": "æœªå®Œæˆ",
                "strengths": [],
                "weaknesses": [],
                "suggestions": ["é¢è¯•æœªå®Œæˆï¼Œæ— æ³•ç”Ÿæˆè¯„ä¼°"]
            }
        }

    # ä»è½®æ¬¡è¯„ä¼°æ•°æ®ä¸­æ±‡æ€»
    total_technical = 0
    total_communication = 0
    total_problem_solving = 0
    total_cultural_fit = 0
    count = 0

    for r in rounds:
        if r.evaluation_data:
            total_technical += r.evaluation_data.get("technical_score", 0)
            total_communication += r.evaluation_data.get("communication_score", 0)
            total_problem_solving += r.evaluation_data.get("problem_solving_score", 0)
            total_cultural_fit += r.evaluation_data.get("cultural_fit_score", 0)
            count += 1

    if count > 0:
        avg_technical = round(total_technical / count, 1)
        avg_communication = round(total_communication / count, 1)
        avg_problem_solving = round(total_problem_solving / count, 1)
        avg_cultural_fit = round(total_cultural_fit / count, 1)
        total_score = round(avg_technical + avg_communication + avg_problem_solving + avg_cultural_fit, 1)

        # ç¡®å®šè¡¨ç°ç­‰çº§
        if total_score >= 32:
            level = "ä¼˜ç§€"
        elif total_score >= 24:
            level = "è‰¯å¥½"
        elif total_score >= 16:
            level = "åˆæ ¼"
        else:
            level = "å¾…æå‡"
    else:
        avg_technical = avg_communication = avg_problem_solving = avg_cultural_fit = 0
        total_score = 0
        level = "æœªè¯„ä¼°"

    return {
        "evaluation": {
            "technical_score": avg_technical,
            "communication_score": avg_communication,
            "problem_solving_score": avg_problem_solving,
            "cultural_fit_score": avg_cultural_fit,
            "total_score": total_score,
            "performance_level": level,
            "strengths": [],
            "weaknesses": [],
            "suggestions": []
        }
    }


@router.get("/sessions/{session_id}/download-pdf")
async def download_pdf_report(
    session_id: str,
    db: Session = Depends(get_digital_interviewer_db)
):
    """ä¸‹è½½é¢è¯•æŠ¥å‘ŠPDF"""
    from backend.models.db_models import InterviewRound, InterviewEvaluation
    from fastapi.responses import Response
    from datetime import datetime

    # è·å–ä¼šè¯
    session = db.query(InterviewSession).filter_by(session_id=session_id).first()
    if not session:
        raise HTTPException(status_code=404, detail="ä¼šè¯ä¸å­˜åœ¨")

    # è·å–è½®æ¬¡æ•°æ®
    rounds = db.query(InterviewRound).filter_by(session_id=session.id).order_by(InterviewRound.round_number).all()

    # è·å–è¯„ä¼°æ•°æ®
    evaluation = db.query(InterviewEvaluation).filter_by(session_id=session.id).first()

    # å¦‚æœæ²¡æœ‰è¯„ä¼°ï¼Œä»è½®æ¬¡æ±‡æ€»
    if not evaluation:
        total_technical = total_communication = total_problem_solving = total_cultural_fit = 0
        count = 0
        for r in rounds:
            if r.evaluation_data:
                total_technical += r.evaluation_data.get("technical_score", 0)
                total_communication += r.evaluation_data.get("communication_score", 0)
                total_problem_solving += r.evaluation_data.get("problem_solving_score", 0)
                total_cultural_fit += r.evaluation_data.get("cultural_fit_score", 0)
                count += 1

        if count > 0:
            eval_data = {
                "technical_score": round(total_technical / count, 1),
                "communication_score": round(total_communication / count, 1),
                "problem_solving_score": round(total_problem_solving / count, 1),
                "cultural_fit_score": round(total_cultural_fit / count, 1),
            }
            eval_data["total_score"] = round(sum(eval_data.values()), 1)
        else:
            eval_data = {
                "technical_score": 0,
                "communication_score": 0,
                "problem_solving_score": 0,
                "cultural_fit_score": 0,
                "total_score": 0,
            }
    else:
        eval_data = {
            "technical_score": evaluation.technical_score or 0,
            "communication_score": evaluation.communication_score or 0,
            "problem_solving_score": evaluation.problem_solving_score or 0,
            "cultural_fit_score": evaluation.cultural_fit_score or 0,
            "total_score": evaluation.total_score or 0,
        }

    # ç”ŸæˆHTMLå†…å®¹
    rounds_html = ""
    for i, r in enumerate(rounds):
        eval_info = ""
        if r.evaluation_data:
            eval_info = f"""
            <p><strong>è¯„åˆ†:</strong> æŠ€æœ¯ {r.evaluation_data.get('technical_score', 0)}/10 |
            æ²Ÿé€š {r.evaluation_data.get('communication_score', 0)}/10 |
            é—®é¢˜è§£å†³ {r.evaluation_data.get('problem_solving_score', 0)}/10</p>
            """
        rounds_html += f"""
        <div class="round">
            <h3>ç¬¬ {i + 1} è½®</h3>
            <p><strong>é—®é¢˜:</strong> {r.question}</p>
            <p><strong>å›ç­”:</strong> {r.answer or 'æœªå›ç­”'}</p>
            {eval_info}
        </div>
        """

    interview_type_map = {
        "technical": "æŠ€æœ¯é¢è¯•",
        "hr": "HRé¢è¯•",
        "behavioral": "è¡Œä¸ºé¢è¯•"
    }

    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="utf-8">
        <title>é¢è¯•æŠ¥å‘Š</title>
        <style>
            @page {{ size: A4; margin: 2cm; }}
            body {{ font-family: 'SimSun', 'Microsoft YaHei', sans-serif; line-height: 1.6; color: #333; }}
            h1 {{ color: #1976d2; border-bottom: 2px solid #1976d2; padding-bottom: 10px; }}
            h2 {{ color: #333; margin-top: 30px; }}
            h3 {{ color: #1976d2; }}
            .info-grid {{ display: grid; grid-template-columns: 1fr 1fr; gap: 10px; margin: 20px 0; }}
            .info-item {{ padding: 10px; background: #f5f5f5; border-radius: 5px; }}
            .scores {{ display: grid; grid-template-columns: repeat(4, 1fr); gap: 15px; margin: 20px 0; }}
            .score-item {{ text-align: center; padding: 15px; background: #e3f2fd; border-radius: 8px; }}
            .score-value {{ font-size: 24px; font-weight: bold; color: #1976d2; }}
            .total-score {{ text-align: center; padding: 20px; background: #1976d2; color: white; border-radius: 10px; margin: 20px 0; }}
            .total-score .value {{ font-size: 48px; font-weight: bold; }}
            .round {{ margin: 20px 0; padding: 15px; background: #fafafa; border-left: 4px solid #1976d2; border-radius: 0 8px 8px 0; }}
            .footer {{ margin-top: 40px; text-align: center; color: #666; font-size: 12px; }}
        </style>
    </head>
    <body>
        <h1>é¢è¯•æŠ¥å‘Š</h1>

        <h2>åŸºæœ¬ä¿¡æ¯</h2>
        <div class="info-grid">
            <div class="info-item"><strong>å€™é€‰äºº:</strong> {session.candidate_name or 'æœªæä¾›'}</div>
            <div class="info-item"><strong>é¢è¯•å®˜:</strong> {session.interviewer_name}</div>
            <div class="info-item"><strong>é¢è¯•ç±»å‹:</strong> {interview_type_map.get(session.interview_type, session.interview_type)}</div>
            <div class="info-item"><strong>é¢è¯•æ—¶é—´:</strong> {session.created_at.strftime('%Y-%m-%d %H:%M')}</div>
        </div>

        <h2>ç»¼åˆè¯„åˆ†</h2>
        <div class="total-score">
            <div class="value">{eval_data['total_score']}/40</div>
            <div>ç»¼åˆå¾—åˆ†</div>
        </div>
        <div class="scores">
            <div class="score-item">
                <div class="score-value">{eval_data['technical_score']}</div>
                <div>æŠ€æœ¯èƒ½åŠ›</div>
            </div>
            <div class="score-item">
                <div class="score-value">{eval_data['communication_score']}</div>
                <div>æ²Ÿé€šèƒ½åŠ›</div>
            </div>
            <div class="score-item">
                <div class="score-value">{eval_data['problem_solving_score']}</div>
                <div>é—®é¢˜è§£å†³</div>
            </div>
            <div class="score-item">
                <div class="score-value">{eval_data['cultural_fit_score']}</div>
                <div>æ–‡åŒ–åŒ¹é…</div>
            </div>
        </div>

        <h2>é¢è¯•è¯¦æƒ…</h2>
        {rounds_html if rounds_html else '<p>æš‚æ— é¢è¯•è½®æ¬¡æ•°æ®</p>'}

        <div class="footer">
            <p>æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            <p>VividCrowd AI æ•°å­—é¢è¯•å®˜ç³»ç»Ÿ</p>
        </div>
    </body>
    </html>
    """

    # å°è¯•ä½¿ç”¨ WeasyPrint ç”Ÿæˆ PDF
    try:
        from weasyprint import HTML
        pdf_bytes = HTML(string=html_content).write_pdf()
        return Response(
            content=pdf_bytes,
            media_type="application/pdf",
            headers={
                "Content-Disposition": f"attachment; filename=interview_report_{session_id}.pdf"
            }
        )
    except ImportError:
        # å¦‚æœæ²¡æœ‰å®‰è£… WeasyPrintï¼Œè¿”å› HTML
        return Response(
            content=html_content.encode('utf-8'),
            media_type="text/html",
            headers={
                "Content-Disposition": f"attachment; filename=interview_report_{session_id}.html"
            }
        )


@router.websocket("/training/ws/{session_id}")
async def interview_websocket(websocket: WebSocket, session_id: str):
    """é¢è¯•WebSocketç«¯ç‚¹ - å®Œæ•´å®ç°"""
    await websocket.accept()
    db = None
    orchestrator = None
    interview_active = False

    try:
        # 1. è·å–æ•°æ®åº“ä¼šè¯
        db = next(get_digital_interviewer_db())

        # 2. åˆå§‹åŒ–ç¼–æ’å™¨ï¼ˆä¼ é€’API Keyï¼‰
        from backend.apps.digital_interviewer.services.interviewer_orchestrator import InterviewOrchestrator
        from backend.core.config import settings
        orchestrator = InterviewOrchestrator(
            db=db,
            api_key=settings.DASHSCOPE_API_KEY,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
        )

        # 3. ç­‰å¾…å®¢æˆ·ç«¯å‘é€å¼€å§‹ä¿¡å·
        await websocket.send_json({
            "type": "ready",
            "message": "è¿æ¥æˆåŠŸï¼Œç­‰å¾…å¼€å§‹é¢è¯•"
        })

        # 4. é¢è¯•å¾ªç¯
        while True:
            # æ¥æ”¶æ¶ˆæ¯
            data = await websocket.receive_json()

            if data.get("type") == "start_interview":
                # å¼€å§‹é¢è¯•å¹¶æ¨é€ç¬¬ä¸€ä¸ªé—®é¢˜
                if not interview_active:
                    try:
                        # è·å–é¢ç»é…ç½®ï¼ˆä»å®¢æˆ·ç«¯ä¼ é€’æˆ–ä»ä¼šè¯ä¸­è·å–ï¼‰
                        experience_set_ids = data.get("experience_set_ids", [])
                        experience_mode = data.get("experience_mode", "none")

                        first_question = await orchestrator.start_interview(
                            session_id,
                            experience_set_ids=experience_set_ids,
                            experience_mode=experience_mode
                        )
                        interview_active = True
                        await websocket.send_json({
                            "type": "question",
                            "content": first_question["question"],
                            "round_number": first_question["round_number"],
                            "video_state": "speaking"
                        })
                    except Exception as e:
                        await websocket.send_json({
                            "type": "error",
                            "message": f"å¼€å§‹é¢è¯•å¤±è´¥: {str(e)}"
                        })

            elif data.get("type") == "end_interview":
                # ç»“æŸé¢è¯•
                if interview_active:
                    try:
                        final_eval = await orchestrator.end_interview(session_id)
                        await websocket.send_json({
                            "type": "interview_end",
                            "evaluation": final_eval,
                            "message": "é¢è¯•å·²ç»“æŸ"
                        })
                        interview_active = False
                        break
                    except Exception as e:
                        await websocket.send_json({
                            "type": "error",
                            "message": f"ç»“æŸé¢è¯•å¤±è´¥: {str(e)}"
                        })

            elif data.get("type") == "answer" and interview_active:
                # æ¨é€listeningçŠ¶æ€
                await websocket.send_json({
                    "type": "video_state",
                    "state": "listening"
                })

                # å¤„ç†å›ç­”
                try:
                    result = await orchestrator.process_answer(
                        session_id=session_id,
                        answer=data.get("content", "")
                    )

                    # æ¨é€thinkingçŠ¶æ€
                    await websocket.send_json({
                        "type": "video_state",
                        "state": "thinking"
                    })

                    # æ¨é€è¯„ä¼°ç»“æœ
                    await websocket.send_json({
                        "type": "evaluation",
                        "data": result.get("evaluation", {})
                    })

                    # æ£€æŸ¥æ˜¯å¦ç»§ç»­
                    if result.get("action") == "continue":
                        # æ¨é€ä¸‹ä¸€ä¸ªé—®é¢˜
                        await websocket.send_json({
                            "type": "question",
                            "content": result["question"],
                            "round_number": result["round_number"],
                            "video_state": "speaking"
                        })
                    else:
                        # é¢è¯•ç»“æŸ
                        await websocket.send_json({
                            "type": "interview_end",
                            "evaluation": result.get("final_evaluation", {}),
                            "message": "é¢è¯•å·²ç»“æŸ"
                        })
                        break

                except Exception as e:
                    await websocket.send_json({
                        "type": "error",
                        "message": f"å¤„ç†å›ç­”å¤±è´¥: {str(e)}"
                    })

    except WebSocketDisconnect:
        # WebSocketæ–­å¼€æ—¶ï¼Œæ›´æ–°ä¼šè¯çŠ¶æ€ä¸ºcompleted
        if db:
            try:
                session = db.query(InterviewSession).filter_by(session_id=session_id).first()
                if session and session.status == "in_progress":
                    from datetime import datetime
                    session.status = "completed"
                    session.completed_at = datetime.utcnow()
                    if session.started_at:
                        session.duration_seconds = int((session.completed_at - session.started_at).total_seconds())
                    db.commit()
            except Exception as e:
                print(f"æ›´æ–°ä¼šè¯çŠ¶æ€å¤±è´¥: {e}")
    except Exception as e:
        try:
            await websocket.send_json({
                "type": "error",
                "message": f"WebSocketé”™è¯¯: {str(e)}"
            })
        except:
            pass
    finally:
        # ç¡®ä¿ä¼šè¯çŠ¶æ€è¢«æ›´æ–°
        if db:
            try:
                session = db.query(InterviewSession).filter_by(session_id=session_id).first()
                if session and session.status == "in_progress":
                    from datetime import datetime
                    session.status = "completed"
                    session.completed_at = datetime.utcnow()
                    if session.started_at:
                        session.duration_seconds = int((session.completed_at - session.started_at).total_seconds())
                    db.commit()
            except:
                pass
            db.close()


# ==================== è¯­éŸ³æœåŠ¡ç«¯ç‚¹ ====================

@router.post("/audio/transcribe")
async def transcribe_audio_endpoint(file: UploadFile = File(...)):
    """éŸ³é¢‘è½¬æ–‡å­— (ASR) - ç”¨äºè¯†åˆ«å€™é€‰äººçš„è¯­éŸ³å›ç­”"""
    from backend.apps.digital_customer.services.audio_service import transcribe_audio
    from loguru import logger

    try:
        content = await file.read()
        extension = file.filename.split(".")[-1] if "." in file.filename else "wav"
        text = await transcribe_audio(content, extension)
        return {"text": text}
    except Exception as e:
        logger.error(f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/audio/synthesize")
async def synthesize_audio_endpoint(
    text: str = Form(...),
    voice: str = Form("longxiaochun")
):
    """æ–‡å­—è½¬éŸ³é¢‘ (TTS) - ç”¨äºé¢è¯•å®˜è¯­éŸ³æé—®"""
    from backend.apps.digital_customer.services.audio_service import synthesize_audio
    from fastapi.responses import Response
    from loguru import logger

    try:
        audio_data = await synthesize_audio(text, voice)
        return Response(content=audio_data, media_type="audio/mpeg")
    except Exception as e:
        logger.error(f"è¯­éŸ³åˆæˆå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/sessions")
async def get_interview_sessions(db: Session = Depends(get_digital_interviewer_db)):
    """è·å–æ‰€æœ‰é¢è¯•ä¼šè¯åˆ—è¡¨"""
    sessions = db.query(InterviewSession).order_by(InterviewSession.created_at.desc()).all()
    return {"sessions": [session.to_dict() for session in sessions]}


# ==================== é¢ç»ç®¡ç†ç«¯ç‚¹ ====================

@router.post("/experience-sets/upload-stream")
async def upload_experience_set_stream(
    name: str = Form(...),
    interview_type: str = Form("technical"),
    description: str = Form(None),
    company: str = Form(None),
    position: str = Form(None),
    file: UploadFile = File(...),
    db: Session = Depends(get_digital_interviewer_db)
):
    """ä¸Šä¼ PDFé¢ç»å¹¶åˆ›å»ºé¢ç»é›†ï¼ˆSSEæµå¼è¿”å›è¿›åº¦ï¼‰"""
    from fastapi.responses import StreamingResponse
    from backend.core.config import settings
    from backend.apps.digital_interviewer.services.experience_parser import ExperienceParser
    from loguru import logger
    import json as json_module

    # å…ˆè¯»å–æ–‡ä»¶å†…å®¹ï¼ˆåœ¨ç”Ÿæˆå™¨å¤–éƒ¨è¯»å–ï¼Œé¿å…æ–‡ä»¶å…³é—­é—®é¢˜ï¼‰
    file_content = await file.read()
    filename = file.filename

    async def generate_progress():
        try:
            logger.info(f"å¼€å§‹ä¸Šä¼ é¢ç»: {filename}")

            # éªŒè¯æ–‡ä»¶ç±»å‹
            if not filename.lower().endswith('.pdf'):
                yield f"data: {json_module.dumps({'type': 'error', 'message': 'åªæ”¯æŒPDFæ–‡ä»¶'})}\n\n"
                return

            # ä¿å­˜æ–‡ä»¶
            file_path = os.path.join(EXPERIENCE_DIR, filename)
            with open(file_path, 'wb') as f:
                f.write(file_content)

            yield f"data: {json_module.dumps({'type': 'progress', 'current': 0, 'total': 100, 'message': 'æ–‡ä»¶å·²ä¿å­˜ï¼Œå¼€å§‹è§£æ...'})}\n\n"

            # åˆ›å»ºè§£æå™¨
            parser = ExperienceParser(
                api_key=settings.DASHSCOPE_API_KEY,
                base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
            )

            # æµå¼è§£æ
            parse_result = None
            async for progress in parser.parse_pdf_stream(file_path):
                if progress["type"] == "complete":
                    parse_result = progress["result"]
                yield f"data: {json_module.dumps(progress)}\n\n"

            if not parse_result:
                yield f"data: {json_module.dumps({'type': 'error', 'message': 'è§£æå¤±è´¥'})}\n\n"
                return

            # ä¿å­˜åˆ°æ•°æ®åº“
            yield f"data: {json_module.dumps({'type': 'progress', 'current': 100, 'total': 100, 'message': 'æ­£åœ¨ä¿å­˜åˆ°æ•°æ®åº“...'})}\n\n"

            experience_set = InterviewExperienceSet(
                name=name,
                description=description or parse_result.get("title"),
                source_filename=filename,
                company=company or parse_result.get("company"),
                position=position or parse_result.get("position"),
                interview_type=interview_type or parse_result.get("interview_type", "technical"),
                question_count=len(parse_result.get("questions", [])),
                is_active=True
            )
            db.add(experience_set)
            db.flush()

            # ä¿å­˜é—®é¢˜
            for q in parse_result.get("questions", []):
                knowledge = InterviewKnowledge(
                    interview_type=interview_type,
                    category=q.get("category"),
                    content=q.get("question", ""),
                    difficulty_level=q.get("difficulty"),
                    source_filename=filename,
                    experience_set_id=experience_set.id,
                    question_text=q.get("question", ""),
                    reference_answer=q.get("answer"),
                    tags=json_module.dumps(q.get("tags")) if q.get("tags") else None
                )
                db.add(knowledge)

            db.commit()
            db.refresh(experience_set)

            yield f"data: {json_module.dumps({'type': 'done', 'message': 'ä¸Šä¼ æˆåŠŸ', 'experience_set': experience_set.to_dict()})}\n\n"

        except Exception as e:
            logger.error(f"ä¸Šä¼ é¢ç»å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            yield f"data: {json_module.dumps({'type': 'error', 'message': str(e)})}\n\n"

    return StreamingResponse(
        generate_progress(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


@router.post("/experience-sets/upload")
async def upload_experience_set(
    name: str = Form(...),
    interview_type: str = Form("technical"),
    description: str = Form(None),
    company: str = Form(None),
    position: str = Form(None),
    file: UploadFile = File(...),
    db: Session = Depends(get_digital_interviewer_db)
):
    """ä¸Šä¼ PDFé¢ç»å¹¶åˆ›å»ºé¢ç»é›†"""
    from loguru import logger
    from backend.core.config import settings

    try:
        logger.info(f"å¼€å§‹ä¸Šä¼ é¢ç»: {file.filename}")

        # éªŒè¯æ–‡ä»¶ç±»å‹
        if not file.filename.lower().endswith('.pdf'):
            raise HTTPException(status_code=400, detail="åªæ”¯æŒPDFæ–‡ä»¶")

        # ä¿å­˜æ–‡ä»¶
        content = await file.read()
        file_path = os.path.join(EXPERIENCE_DIR, file.filename)
        with open(file_path, 'wb') as f:
            f.write(content)
        logger.info(f"æ–‡ä»¶å·²ä¿å­˜åˆ°: {file_path}")

        # åˆ›å»ºé¢ç»é›†
        service = ExperienceService(
            db=db,
            api_key=settings.DASHSCOPE_API_KEY,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
        )

        experience_set = await service.create_experience_set(
            name=name,
            file_path=file_path,
            interview_type=interview_type,
            description=description,
            company=company,
            position=position
        )

        return {
            "message": "ä¸Šä¼ æˆåŠŸ",
            "experience_set": experience_set.to_dict()
        }

    except Exception as e:
        logger.error(f"ä¸Šä¼ é¢ç»å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/experience-sets")
async def list_experience_sets(
    interview_type: str = None,
    db: Session = Depends(get_digital_interviewer_db)
):
    """è·å–é¢ç»é›†åˆ—è¡¨"""
    service = ExperienceService(db=db)
    sets = service.get_experience_sets(interview_type=interview_type)
    return {"experience_sets": [s.to_dict() for s in sets]}


@router.get("/experience-sets/{set_id}")
async def get_experience_set(
    set_id: int,
    db: Session = Depends(get_digital_interviewer_db)
):
    """è·å–å•ä¸ªé¢ç»é›†è¯¦æƒ…"""
    service = ExperienceService(db=db)
    experience_set = service.get_experience_set(set_id)
    if not experience_set:
        raise HTTPException(status_code=404, detail="é¢ç»é›†ä¸å­˜åœ¨")
    return {"experience_set": experience_set.to_dict()}


@router.get("/experience-sets/{set_id}/questions")
async def get_experience_questions(
    set_id: int,
    db: Session = Depends(get_digital_interviewer_db)
):
    """è·å–é¢ç»é›†ä¸­çš„é—®é¢˜"""
    service = ExperienceService(db=db)
    questions = service.get_questions_by_set(set_id)
    return {"questions": [q.to_dict() for q in questions]}


@router.delete("/experience-sets/{set_id}")
async def delete_experience_set(
    set_id: int,
    db: Session = Depends(get_digital_interviewer_db)
):
    """åˆ é™¤é¢ç»é›†"""
    service = ExperienceService(db=db)
    success = service.delete_experience_set(set_id)
    if not success:
        raise HTTPException(status_code=404, detail="é¢ç»é›†ä¸å­˜åœ¨")
    return {"message": "åˆ é™¤æˆåŠŸ"}
